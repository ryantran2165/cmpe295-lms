{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "0ffa99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.transforms.functional import rotate, hflip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "1357000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathSymbolsDataset(Dataset):\n",
    "    def __init__(self, img_labels, transform=None, target_transform=None):\n",
    "        self.img_labels = img_labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "        im = cv2.imread(img_path)\n",
    "\n",
    "        im = cv2.bitwise_not(im)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #     cnts = cv2.findContours(im, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #     cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        #     for c in cnts:\n",
    "        #         cv2.drawContours(im, [c], -1, (255,255,255), thickness=2)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "        im = cv2.dilate(im, kernel, iterations=1)\n",
    "\n",
    "        im = cv2.resize(im, (20, 20))\n",
    "        border = 4\n",
    "        im = cv2.copyMakeBorder(\n",
    "            im, border, border, border, border, cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "        )\n",
    "\n",
    "        image = torch.from_numpy(im.astype(\"float32\")).unsqueeze(0)\n",
    "\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.tensor(label).type(torch.LongTensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "3bc9b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num math symbols: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/math_symbols/-/-_100005.jpg</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/math_symbols/-/-_100007.jpg</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/math_symbols/-/-_100009.jpg</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/math_symbols/-/-_100015.jpg</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/math_symbols/-/-_100021.jpg</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109806</th>\n",
       "      <td>data/math_symbols/times/times_95436.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109807</th>\n",
       "      <td>data/math_symbols/times/times_95489.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109808</th>\n",
       "      <td>data/math_symbols/times/times_9589.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109809</th>\n",
       "      <td>data/math_symbols/times/times_9755.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109810</th>\n",
       "      <td>data/math_symbols/times/times_9881.jpg</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109811 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           path  label\n",
       "0              data/math_symbols/-/-_100005.jpg     62\n",
       "1              data/math_symbols/-/-_100007.jpg     62\n",
       "2              data/math_symbols/-/-_100009.jpg     62\n",
       "3              data/math_symbols/-/-_100015.jpg     62\n",
       "4              data/math_symbols/-/-_100021.jpg     62\n",
       "...                                         ...    ...\n",
       "109806  data/math_symbols/times/times_95436.jpg     74\n",
       "109807  data/math_symbols/times/times_95489.jpg     74\n",
       "109808   data/math_symbols/times/times_9589.jpg     74\n",
       "109809   data/math_symbols/times/times_9755.jpg     74\n",
       "109810   data/math_symbols/times/times_9881.jpg     74\n",
       "\n",
       "[109811 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109811 entries, 0 to 109810\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   path    109811 non-null  object\n",
      " 1   label   109811 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math symbols dataset: 109811 torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# name = \"emnistbyclass\"\n",
    "# name = \"mnist\"\n",
    "# name = \"mathsymbols\"\n",
    "# name = \"mnist_mathsymbols\"\n",
    "name = \"emnistbyclass_mathsymbols\"\n",
    "\n",
    "# EMNIST dataset\n",
    "split = \"byclass\"\n",
    "# split = 'bymerge'\n",
    "# split = 'balanced'\n",
    "# split = 'letters'\n",
    "# split = 'digits'\n",
    "# split = \"mnist\"\n",
    "emnist_train_data = datasets.EMNIST(\n",
    "    root=\"data\",\n",
    "    split=split,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=Compose([lambda img: rotate(img, -90), lambda img: hflip(img), ToTensor()]),\n",
    "    target_transform=Lambda(lambda y: torch.tensor(y)),\n",
    ")\n",
    "emnist_test_data = datasets.EMNIST(\n",
    "    root=\"data\",\n",
    "    split=split,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=Compose([lambda img: rotate(img, -90), lambda img: hflip(img), ToTensor()]),\n",
    "    target_transform=Lambda(lambda y: torch.tensor(y)),\n",
    ")\n",
    "\n",
    "# Math Symbols dataset\n",
    "math_symbols_root = \"data/math_symbols\"\n",
    "math_symbols = [\"-\", \"!\", \"(\", \")\", \",\", \"[\", \"]\", \"+\", \"=\", \"forward_slash\", \"gt\", \"lt\", \"times\"]\n",
    "print(\"Num math symbols:\", len(math_symbols))\n",
    "data = []\n",
    "for i, symbol in enumerate(math_symbols):\n",
    "    root = f\"{math_symbols_root}/{symbol}\"\n",
    "    files = os.listdir(root)\n",
    "    for file in files:\n",
    "        path = f\"{root}/{file}\"\n",
    "        label = i\n",
    "        data.append([path, label])\n",
    "data = np.array(data)\n",
    "img_labels = pd.DataFrame(columns=[\"path\", \"label\"])\n",
    "img_labels[\"path\"] = data[:, 0]\n",
    "img_labels[\"label\"] = data[:, 1].astype(int)\n",
    "if name == \"mnist_mathsymbols\":\n",
    "    img_labels[\"label\"] = img_labels[\"label\"] + 10\n",
    "elif \"mnist\" in name:\n",
    "    img_labels[\"label\"] = img_labels[\"label\"] + 62\n",
    "display(img_labels)\n",
    "display(img_labels.info())\n",
    "math_symbols_dataset = MathSymbolsDataset(img_labels)\n",
    "print(\"Math symbols dataset:\", len(math_symbols_dataset), math_symbols_dataset[0][0].size())\n",
    "\n",
    "math_symbols_train_size = int(0.8 * len(math_symbols_dataset))\n",
    "math_symbols_test_size = len(math_symbols_dataset) - math_symbols_train_size\n",
    "math_symbols_train_data, math_symbols_test_data = torch.utils.data.random_split(\n",
    "    math_symbols_dataset, [math_symbols_train_size, math_symbols_test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "ed466f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_samples = 0\n",
    "# for symbol in math_symbols:\n",
    "#     path = f'{math_symbols_root}/{symbol}'\n",
    "#     files = os.listdir(path)\n",
    "#     total_samples += len(files)\n",
    "#     idx = np.random.randint(0, len(files))\n",
    "#     file = f'{path}/{files[idx]}'\n",
    "\n",
    "#     im = cv2.imread(file)\n",
    "\n",
    "#     im = cv2.bitwise_not(im)\n",
    "#     im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# #     cnts = cv2.findContours(im, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# #     cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# #     for c in cnts:\n",
    "# #         cv2.drawContours(im, [c], -1, (255,255,255), thickness=2)\n",
    "\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,4))\n",
    "#     im = cv2.dilate(im, kernel, iterations=1)\n",
    "\n",
    "#     im = cv2.resize(im, (20, 20))\n",
    "#     border = 4\n",
    "#     im = cv2.copyMakeBorder(im, border, border, border, border, cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "#     print(im.shape)\n",
    "#     plt.imshow(im, cmap=\"gray\")\n",
    "#     print(file)\n",
    "\n",
    "# print('total samples:', total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "14b1a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"mnist\" in name and \"symbols\" not in name:\n",
    "    train_data = emnist_train_data\n",
    "    test_data = emnist_test_data\n",
    "elif \"mnist\" not in name and \"symbols\" in name:\n",
    "    train_data = math_symbols_train_data\n",
    "    test_data = math_symbols_test_data\n",
    "else:\n",
    "    train_data = ConcatDataset([emnist_train_data, math_symbols_train_data])\n",
    "    test_data = ConcatDataset([emnist_test_data, math_symbols_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "f0f9e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', '!', '(', ')', ',', '[', ']', '+', '=', 'forward_slash', 'gt', 'lt', 'times']\n"
     ]
    }
   ],
   "source": [
    "if name == \"mnist_mathsymbols\":\n",
    "    class_names = [str(num) for num in range(10)] + math_symbols\n",
    "elif \"mnist\" in name and \"symbols\" not in name:\n",
    "    class_names = (\n",
    "        [str(num) for num in range(10)]\n",
    "        + [chr(capital) for capital in range(ord(\"A\"), ord(\"Z\") + 1)]\n",
    "        + [chr(lower) for lower in range(ord(\"a\"), ord(\"z\") + 1)]\n",
    "    )\n",
    "elif \"mnist\" not in name and \"symbols\" in name:\n",
    "    class_names = math_symbols\n",
    "else:\n",
    "    class_names = (\n",
    "        [str(num) for num in range(10)]\n",
    "        + [chr(capital) for capital in range(ord(\"A\"), ord(\"Z\") + 1)]\n",
    "        + [chr(lower) for lower in range(ord(\"a\"), ord(\"z\") + 1)]\n",
    "        + math_symbols\n",
    "    )\n",
    "print(len(class_names))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "3c399c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: L\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(train_data))\n",
    "sample_img, sample_label = train_data[idx]\n",
    "plt.imshow(sample_img.reshape(28, 28), cmap=\"gray\")\n",
    "print(\"Label:\", class_names[sample_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "e956f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 75\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# for X, y in test_dataloader:\n",
    "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     break\n",
    "\n",
    "n_classes = len(class_names)\n",
    "print(\"n_classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "89cb1ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout(p=0.4, inplace=False)\n",
      "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.4, inplace=False)\n",
      "    (1): Linear(in_features=25600, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.4, inplace=False)\n",
      "    (5): Linear(in_features=128, out_features=75, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(in_features=64 * 20 * 20, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(in_features=128, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "70b411ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "ffcc675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "e6cb7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            preds += pred.argmax(1).tolist()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "2da2a569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.582236  [   64/785780]\n",
      "loss: 1.344387  [ 6464/785780]\n",
      "loss: 0.924367  [12864/785780]\n",
      "loss: 0.890122  [19264/785780]\n",
      "loss: 0.765667  [25664/785780]\n",
      "loss: 0.668570  [32064/785780]\n",
      "loss: 0.932734  [38464/785780]\n",
      "loss: 0.678241  [44864/785780]\n",
      "loss: 0.658680  [51264/785780]\n",
      "loss: 0.718621  [57664/785780]\n",
      "loss: 0.646751  [64064/785780]\n",
      "loss: 0.509588  [70464/785780]\n",
      "loss: 0.708094  [76864/785780]\n",
      "loss: 0.579620  [83264/785780]\n",
      "loss: 0.646760  [89664/785780]\n",
      "loss: 0.568232  [96064/785780]\n",
      "loss: 0.398558  [102464/785780]\n",
      "loss: 0.575463  [108864/785780]\n",
      "loss: 0.419699  [115264/785780]\n",
      "loss: 0.721029  [121664/785780]\n",
      "loss: 0.553227  [128064/785780]\n",
      "loss: 0.420183  [134464/785780]\n",
      "loss: 0.359552  [140864/785780]\n",
      "loss: 0.609379  [147264/785780]\n",
      "loss: 0.362872  [153664/785780]\n",
      "loss: 0.647994  [160064/785780]\n",
      "loss: 0.402719  [166464/785780]\n",
      "loss: 0.452747  [172864/785780]\n",
      "loss: 0.618336  [179264/785780]\n",
      "loss: 0.446103  [185664/785780]\n",
      "loss: 0.350634  [192064/785780]\n",
      "loss: 0.331475  [198464/785780]\n",
      "loss: 0.540497  [204864/785780]\n",
      "loss: 0.473022  [211264/785780]\n",
      "loss: 0.502349  [217664/785780]\n",
      "loss: 0.407796  [224064/785780]\n",
      "loss: 0.478038  [230464/785780]\n",
      "loss: 0.472595  [236864/785780]\n",
      "loss: 0.366381  [243264/785780]\n",
      "loss: 0.680749  [249664/785780]\n",
      "loss: 0.494725  [256064/785780]\n",
      "loss: 0.320420  [262464/785780]\n",
      "loss: 0.382050  [268864/785780]\n",
      "loss: 0.611044  [275264/785780]\n",
      "loss: 0.481741  [281664/785780]\n",
      "loss: 0.520979  [288064/785780]\n",
      "loss: 0.502601  [294464/785780]\n",
      "loss: 0.327800  [300864/785780]\n",
      "loss: 0.311590  [307264/785780]\n",
      "loss: 0.702439  [313664/785780]\n",
      "loss: 0.330328  [320064/785780]\n",
      "loss: 0.600559  [326464/785780]\n",
      "loss: 0.353230  [332864/785780]\n",
      "loss: 0.581154  [339264/785780]\n",
      "loss: 0.355764  [345664/785780]\n",
      "loss: 0.453548  [352064/785780]\n",
      "loss: 0.310662  [358464/785780]\n",
      "loss: 0.364386  [364864/785780]\n",
      "loss: 0.233278  [371264/785780]\n",
      "loss: 0.281524  [377664/785780]\n",
      "loss: 0.321462  [384064/785780]\n",
      "loss: 0.512843  [390464/785780]\n",
      "loss: 0.474310  [396864/785780]\n",
      "loss: 0.222438  [403264/785780]\n",
      "loss: 0.580996  [409664/785780]\n",
      "loss: 0.442345  [416064/785780]\n",
      "loss: 0.324873  [422464/785780]\n",
      "loss: 0.490487  [428864/785780]\n",
      "loss: 0.388329  [435264/785780]\n",
      "loss: 0.533215  [441664/785780]\n",
      "loss: 0.338572  [448064/785780]\n",
      "loss: 0.459577  [454464/785780]\n",
      "loss: 0.503070  [460864/785780]\n",
      "loss: 0.567372  [467264/785780]\n",
      "loss: 0.412862  [473664/785780]\n",
      "loss: 0.316473  [480064/785780]\n",
      "loss: 0.389432  [486464/785780]\n",
      "loss: 0.354820  [492864/785780]\n",
      "loss: 0.314712  [499264/785780]\n",
      "loss: 0.255755  [505664/785780]\n",
      "loss: 0.630343  [512064/785780]\n",
      "loss: 0.670591  [518464/785780]\n",
      "loss: 0.238679  [524864/785780]\n",
      "loss: 0.428686  [531264/785780]\n",
      "loss: 0.504459  [537664/785780]\n",
      "loss: 0.330809  [544064/785780]\n",
      "loss: 0.533257  [550464/785780]\n",
      "loss: 0.486705  [556864/785780]\n",
      "loss: 0.453618  [563264/785780]\n",
      "loss: 0.413401  [569664/785780]\n",
      "loss: 0.391347  [576064/785780]\n",
      "loss: 0.409979  [582464/785780]\n",
      "loss: 0.435565  [588864/785780]\n",
      "loss: 0.383377  [595264/785780]\n",
      "loss: 0.265167  [601664/785780]\n",
      "loss: 0.325137  [608064/785780]\n",
      "loss: 0.386748  [614464/785780]\n",
      "loss: 0.403659  [620864/785780]\n",
      "loss: 0.466479  [627264/785780]\n",
      "loss: 0.409623  [633664/785780]\n",
      "loss: 0.264009  [640064/785780]\n",
      "loss: 0.222244  [646464/785780]\n",
      "loss: 0.378185  [652864/785780]\n",
      "loss: 0.273006  [659264/785780]\n",
      "loss: 0.465901  [665664/785780]\n",
      "loss: 0.470232  [672064/785780]\n",
      "loss: 0.273593  [678464/785780]\n",
      "loss: 0.322353  [684864/785780]\n",
      "loss: 0.481257  [691264/785780]\n",
      "loss: 0.299643  [697664/785780]\n",
      "loss: 0.545135  [704064/785780]\n",
      "loss: 0.298741  [710464/785780]\n",
      "loss: 0.408390  [716864/785780]\n",
      "loss: 0.521497  [723264/785780]\n",
      "loss: 0.226144  [729664/785780]\n",
      "loss: 0.357822  [736064/785780]\n",
      "loss: 0.377461  [742464/785780]\n",
      "loss: 0.345506  [748864/785780]\n",
      "loss: 0.387355  [755264/785780]\n",
      "loss: 0.592317  [761664/785780]\n",
      "loss: 0.365669  [768064/785780]\n",
      "loss: 0.203194  [774464/785780]\n",
      "loss: 0.408384  [780864/785780]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.325295 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "b7f7b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model_{name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "cc55c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(f\"model_{name}.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "d7b81573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"F\", Actual: \"F\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec63ff9c70>"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "idx = np.random.randint(0, len(test_data))\n",
    "x, y = test_data[idx]\n",
    "with torch.no_grad():\n",
    "    x = x.unsqueeze(0)\n",
    "    pred = model(x.to(device))\n",
    "    predicted, actual = class_names[pred[0].argmax(0)], class_names[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "plt.imshow(x.reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "3ef38688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.325331 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab490ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe295",
   "language": "python",
   "name": "cmpe295"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
