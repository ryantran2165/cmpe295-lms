{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffa99ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from torchvision.transforms.functional import rotate, hflip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3505c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"emnistbyclass\"\n",
    "# name = \"emnistbalanced\"\n",
    "name = \"emnistbalanced_mathsymbols_custom\"\n",
    "# name = \"mnist\"\n",
    "# name = \"mathsymbols\"\n",
    "# name = \"mnist_mathsymbols\"\n",
    "# name = \"emnistbyclass_mathsymbols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc9b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMNIST dataset\n",
    "# split = \"byclass\"\n",
    "# split = 'bymerge'\n",
    "split = \"balanced\"\n",
    "# split = 'letters'\n",
    "# split = 'digits'\n",
    "# split = \"mnist\"\n",
    "emnist_train_data = datasets.EMNIST(\n",
    "    root=\"data\",\n",
    "    split=split,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=Compose([lambda img: rotate(img, -90), lambda img: hflip(img), ToTensor()]),\n",
    "    target_transform=Lambda(lambda y: torch.tensor(y)),\n",
    ")\n",
    "emnist_test_data = datasets.EMNIST(\n",
    "    root=\"data\",\n",
    "    split=split,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=Compose([lambda img: rotate(img, -90), lambda img: hflip(img), ToTensor()]),\n",
    "    target_transform=Lambda(lambda y: torch.tensor(y)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f9e79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'd', 'e', 'f', 'g', 'h', 'n', 'q', 'r', 't', 'gt', 'colon']\n"
     ]
    }
   ],
   "source": [
    "# math_symbols = [\"-\", \"(\", \")\", \",\", \"[\", \"]\", \"+\", \"=\", \"forward_slash\", \"gt\", \"lt\", \"times\"]\n",
    "math_symbols = [\"gt\"]\n",
    "\n",
    "custom_symbols = [\"colon\"]\n",
    "\n",
    "class_names = []\n",
    "\n",
    "if \"mnist\" in name:\n",
    "    class_names += [str(num) for num in range(10)]\n",
    "\n",
    "if \"emnist\" in name:\n",
    "    class_names += [chr(capital) for capital in range(ord(\"A\"), ord(\"Z\") + 1)]\n",
    "    class_names += [chr(lower) for lower in range(ord(\"a\"), ord(\"z\") + 1)]\n",
    "\n",
    "if \"balanced\" in name:\n",
    "    class_names = [\n",
    "        x\n",
    "        for x in class_names\n",
    "        if x not in {\"c\", \"i\", \"j\", \"k\", \"l\", \"m\", \"o\", \"p\", \"s\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"}\n",
    "    ]\n",
    "\n",
    "if \"math\" in name:\n",
    "    class_names += math_symbols\n",
    "\n",
    "if \"custom\" in name:\n",
    "    class_names += custom_symbols\n",
    "\n",
    "print(len(class_names))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "789552ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/math_symbols/gt/exp1.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/math_symbols/gt/exp1009.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/math_symbols/gt/exp1037.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/math_symbols/gt/exp104081.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/math_symbols/gt/exp104819.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>data/math_symbols/gt/gt_98800.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>data/math_symbols/gt/gt_99628.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>data/math_symbols/gt/gt_99668.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>data/math_symbols/gt/gt_99835.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>data/math_symbols/gt/gt_99942.jpg</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   path  label\n",
       "0         data/math_symbols/gt/exp1.jpg     47\n",
       "1      data/math_symbols/gt/exp1009.jpg     47\n",
       "2      data/math_symbols/gt/exp1037.jpg     47\n",
       "3    data/math_symbols/gt/exp104081.jpg     47\n",
       "4    data/math_symbols/gt/exp104819.jpg     47\n",
       "..                                  ...    ...\n",
       "253   data/math_symbols/gt/gt_98800.jpg     47\n",
       "254   data/math_symbols/gt/gt_99628.jpg     47\n",
       "255   data/math_symbols/gt/gt_99668.jpg     47\n",
       "256   data/math_symbols/gt/gt_99835.jpg     47\n",
       "257   data/math_symbols/gt/gt_99942.jpg     47\n",
       "\n",
       "[258 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 258 entries, 0 to 257\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    258 non-null    object\n",
      " 1   label   258 non-null    int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 3.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math symbols dataset: 258 torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Math Symbols dataset\n",
    "class MathSymbolsDataset(Dataset):\n",
    "    def __init__(self, img_labels, transform=None, target_transform=None):\n",
    "        self.img_labels = img_labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "        im = cv2.imread(img_path)\n",
    "\n",
    "        # Grayscale\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Flip black and white\n",
    "        im = cv2.bitwise_not(im)\n",
    "\n",
    "        # Make lines thicker\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "        im = cv2.dilate(im, kernel, iterations=1)\n",
    "\n",
    "        # Gaussian blur\n",
    "        im = cv2.GaussianBlur(im, ksize=(3, 3), sigmaX=1, sigmaY=1)\n",
    "\n",
    "        # Resize to 24x24\n",
    "        im = cv2.resize(im, (24, 24), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Add 2 pixel border for total size of 28x28\n",
    "        border = 2\n",
    "        im = cv2.copyMakeBorder(\n",
    "            im, border, border, border, border, cv2.BORDER_CONSTANT, value=(0, 0, 0)\n",
    "        )\n",
    "\n",
    "        # Normalize\n",
    "        im = im / 255\n",
    "\n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(im.astype(\"float32\")).unsqueeze(0)\n",
    "\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.tensor(label).type(torch.LongTensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "math_symbols_root = \"data/math_symbols\"\n",
    "\n",
    "# EMNIST balanced has 2400 train samples per class\n",
    "target_samples = 2400\n",
    "\n",
    "data = []\n",
    "for i, symbol in enumerate(math_symbols):\n",
    "    root = f\"{math_symbols_root}/{symbol}\"\n",
    "    files = os.listdir(root)\n",
    "    for file in files:\n",
    "        path = f\"{root}/{file}\"\n",
    "        label = i\n",
    "        data.append([path, label])\n",
    "data = np.array(data)\n",
    "\n",
    "img_labels = pd.DataFrame(columns=[\"path\", \"label\"])\n",
    "img_labels[\"path\"] = data[:, 0]\n",
    "img_labels[\"label\"] = data[:, 1].astype(int)\n",
    "\n",
    "offset = 0\n",
    "if \"mnist\" in name:\n",
    "    offset += 10\n",
    "if \"emnist\" in name:\n",
    "    offset += 52\n",
    "if \"balanced\" in name:\n",
    "    offset -= 15\n",
    "img_labels[\"label\"] = img_labels[\"label\"] + offset\n",
    "display(img_labels)\n",
    "display(img_labels.info())\n",
    "\n",
    "math_symbols_dataset = MathSymbolsDataset(img_labels)\n",
    "print(\"Math symbols dataset:\", len(math_symbols_dataset), math_symbols_dataset[0][0].size())\n",
    "\n",
    "math_symbols_train_size = int(0.9 * len(math_symbols_dataset))\n",
    "math_symbols_test_size = len(math_symbols_dataset) - math_symbols_train_size\n",
    "math_symbols_train_data, math_symbols_test_data = torch.utils.data.random_split(\n",
    "    math_symbols_dataset, [math_symbols_train_size, math_symbols_test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e62cb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/custom_symbols/colon/colon_0.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/custom_symbols/colon/colon_1.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/custom_symbols/colon/colon_2.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/custom_symbols/colon/colon_3.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/custom_symbols/colon/colon_4.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>data/custom_symbols/colon/aug/colon_9_aug5.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>data/custom_symbols/colon/aug/colon_9_aug6.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>data/custom_symbols/colon/aug/colon_9_aug7.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>data/custom_symbols/colon/aug/colon_9_aug8.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>data/custom_symbols/colon/aug/colon_9_aug9.jpg</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               path  label\n",
       "0             data/custom_symbols/colon/colon_0.jpg     48\n",
       "1             data/custom_symbols/colon/colon_1.jpg     48\n",
       "2             data/custom_symbols/colon/colon_2.jpg     48\n",
       "3             data/custom_symbols/colon/colon_3.jpg     48\n",
       "4             data/custom_symbols/colon/colon_4.jpg     48\n",
       "..                                              ...    ...\n",
       "105  data/custom_symbols/colon/aug/colon_9_aug5.jpg     48\n",
       "106  data/custom_symbols/colon/aug/colon_9_aug6.jpg     48\n",
       "107  data/custom_symbols/colon/aug/colon_9_aug7.jpg     48\n",
       "108  data/custom_symbols/colon/aug/colon_9_aug8.jpg     48\n",
       "109  data/custom_symbols/colon/aug/colon_9_aug9.jpg     48\n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   path    110 non-null    object\n",
      " 1   label   110 non-null    int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 1.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom symbols dataset: 110 torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Custom Symbols dataset\n",
    "class CustomSymbolsDataset(Dataset):\n",
    "    def __init__(self, img_labels, transform=None, target_transform=None):\n",
    "        self.img_labels = img_labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "\n",
    "        im = cv2.imread(img_path)\n",
    "\n",
    "        # Grayscale\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Normalize\n",
    "        im = im / 255\n",
    "\n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(im.astype(\"float32\")).unsqueeze(0)\n",
    "\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.tensor(label).type(torch.LongTensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "custom_symbols_root = \"data/custom_symbols\"\n",
    "\n",
    "# EMNIST balanced has 2400 train samples per class\n",
    "target_samples = 2400\n",
    "\n",
    "data = []\n",
    "for file in glob.glob(f\"{custom_symbols_root}/**/*.jpg\", recursive=True):\n",
    "    path = file.replace(\"\\\\\", \"/\")\n",
    "    label = i\n",
    "    data.append([path, label])\n",
    "data = np.array(data)\n",
    "\n",
    "img_labels = pd.DataFrame(columns=[\"path\", \"label\"])\n",
    "img_labels[\"path\"] = data[:, 0]\n",
    "img_labels[\"label\"] = data[:, 1].astype(int)\n",
    "\n",
    "offset = 0\n",
    "if \"mnist\" in name:\n",
    "    offset += 10\n",
    "if \"emnist\" in name:\n",
    "    offset += 52\n",
    "if \"balanced\" in name:\n",
    "    offset -= 15\n",
    "if \"math\" in name:\n",
    "    offset += len(math_symbols)\n",
    "img_labels[\"label\"] = img_labels[\"label\"] + offset\n",
    "display(img_labels)\n",
    "display(img_labels.info())\n",
    "\n",
    "custom_symbols_dataset = CustomSymbolsDataset(img_labels)\n",
    "print(\"Custom symbols dataset:\", len(custom_symbols_dataset), custom_symbols_dataset[0][0].size())\n",
    "\n",
    "custom_symbols_train_size = int(0.9 * len(custom_symbols_dataset))\n",
    "custom_symbols_test_size = len(custom_symbols_dataset) - custom_symbols_train_size\n",
    "custom_symbols_train_data, custom_symbols_test_data = torch.utils.data.random_split(\n",
    "    custom_symbols_dataset, [custom_symbols_train_size, custom_symbols_test_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b1a0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "if \"mnist\" in name:\n",
    "    train_data.append(emnist_train_data)\n",
    "    test_data.append(emnist_test_data)\n",
    "\n",
    "if \"math\" in name:\n",
    "    train_data.append(math_symbols_train_data)\n",
    "    test_data.append(math_symbols_test_data)\n",
    "\n",
    "if \"custom\" in name:\n",
    "    train_data.append(custom_symbols_train_data)\n",
    "    test_data.append(custom_symbols_test_data)\n",
    "\n",
    "if len(train_data) == 1:\n",
    "    train_data = train_data[0]\n",
    "    test_data = test_data[0]\n",
    "else:\n",
    "    train_data = ConcatDataset(train_data)\n",
    "    test_data = ConcatDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c399c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: U\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(0, len(train_data))\n",
    "sample_img, sample_label = train_data[idx]\n",
    "plt.imshow(sample_img.reshape(28, 28), cmap=\"gray\")\n",
    "print(\"Label:\", class_names[sample_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e956f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 49\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# for X, y in test_dataloader:\n",
    "#     print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "#     print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "#     break\n",
    "\n",
    "n_classes = len(class_names)\n",
    "print(\"n_classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89cb1ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "CNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): Dropout(p=0.4, inplace=False)\n",
      "    (10): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (14): ReLU()\n",
      "    (15): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.4, inplace=False)\n",
      "    (1): Linear(in_features=25600, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Dropout(p=0.4, inplace=False)\n",
      "    (5): Linear(in_features=128, out_features=49, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(in_features=64 * 20 * 20, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(in_features=128, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b411ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffcc675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6cb7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            preds += pred.argmax(1).tolist()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2da2a569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 3.891289  [   64/113131]\n",
      "loss: 1.145168  [ 6464/113131]\n",
      "loss: 0.817577  [12864/113131]\n",
      "loss: 0.702859  [19264/113131]\n",
      "loss: 0.624923  [25664/113131]\n",
      "loss: 0.556998  [32064/113131]\n",
      "loss: 0.499433  [38464/113131]\n",
      "loss: 0.544676  [44864/113131]\n",
      "loss: 0.607026  [51264/113131]\n",
      "loss: 0.398142  [57664/113131]\n",
      "loss: 0.673238  [64064/113131]\n",
      "loss: 0.490691  [70464/113131]\n",
      "loss: 0.489539  [76864/113131]\n",
      "loss: 0.487327  [83264/113131]\n",
      "loss: 0.312796  [89664/113131]\n",
      "loss: 0.464911  [96064/113131]\n",
      "loss: 0.338532  [102464/113131]\n",
      "loss: 0.358299  [108864/113131]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.385599 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.524999  [   64/113131]\n",
      "loss: 0.253564  [ 6464/113131]\n",
      "loss: 0.413700  [12864/113131]\n",
      "loss: 0.550712  [19264/113131]\n",
      "loss: 0.246696  [25664/113131]\n",
      "loss: 0.396192  [32064/113131]\n",
      "loss: 0.316482  [38464/113131]\n",
      "loss: 0.281391  [44864/113131]\n",
      "loss: 0.385326  [51264/113131]\n",
      "loss: 0.201758  [57664/113131]\n",
      "loss: 0.184124  [64064/113131]\n",
      "loss: 0.387060  [70464/113131]\n",
      "loss: 0.549358  [76864/113131]\n",
      "loss: 0.264001  [83264/113131]\n",
      "loss: 0.587614  [89664/113131]\n",
      "loss: 0.212698  [96064/113131]\n",
      "loss: 0.367240  [102464/113131]\n",
      "loss: 0.380254  [108864/113131]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.346563 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.512127  [   64/113131]\n",
      "loss: 0.304053  [ 6464/113131]\n",
      "loss: 0.335810  [12864/113131]\n",
      "loss: 0.251352  [19264/113131]\n",
      "loss: 0.312059  [25664/113131]\n",
      "loss: 0.613198  [32064/113131]\n",
      "loss: 0.319197  [38464/113131]\n",
      "loss: 0.315319  [44864/113131]\n",
      "loss: 0.261821  [51264/113131]\n",
      "loss: 0.385786  [57664/113131]\n",
      "loss: 0.312235  [64064/113131]\n",
      "loss: 0.307763  [70464/113131]\n",
      "loss: 0.472050  [76864/113131]\n",
      "loss: 0.284874  [83264/113131]\n",
      "loss: 0.300585  [89664/113131]\n",
      "loss: 0.484485  [96064/113131]\n",
      "loss: 0.456816  [102464/113131]\n",
      "loss: 0.275526  [108864/113131]\n",
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.325973 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.398245  [   64/113131]\n",
      "loss: 0.318288  [ 6464/113131]\n",
      "loss: 0.458583  [12864/113131]\n",
      "loss: 0.330306  [19264/113131]\n",
      "loss: 0.418403  [25664/113131]\n",
      "loss: 0.471805  [32064/113131]\n",
      "loss: 0.194162  [38464/113131]\n",
      "loss: 0.257154  [44864/113131]\n",
      "loss: 0.423141  [51264/113131]\n",
      "loss: 0.306932  [57664/113131]\n",
      "loss: 0.254476  [64064/113131]\n",
      "loss: 0.713337  [70464/113131]\n",
      "loss: 0.396932  [76864/113131]\n",
      "loss: 0.298695  [83264/113131]\n",
      "loss: 0.231510  [89664/113131]\n",
      "loss: 0.378160  [96064/113131]\n",
      "loss: 0.246295  [102464/113131]\n",
      "loss: 0.186597  [108864/113131]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.320046 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.277116  [   64/113131]\n",
      "loss: 0.230754  [ 6464/113131]\n",
      "loss: 0.461063  [12864/113131]\n",
      "loss: 0.370573  [19264/113131]\n",
      "loss: 0.240717  [25664/113131]\n",
      "loss: 0.360111  [32064/113131]\n",
      "loss: 0.261269  [38464/113131]\n",
      "loss: 0.273405  [44864/113131]\n",
      "loss: 0.248410  [51264/113131]\n",
      "loss: 0.379515  [57664/113131]\n",
      "loss: 0.112868  [64064/113131]\n",
      "loss: 0.276761  [70464/113131]\n",
      "loss: 0.352244  [76864/113131]\n",
      "loss: 0.298846  [83264/113131]\n",
      "loss: 0.209220  [89664/113131]\n",
      "loss: 0.322625  [96064/113131]\n",
      "loss: 0.304037  [102464/113131]\n",
      "loss: 0.243143  [108864/113131]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.308795 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7f7b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"model_{name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc55c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(f\"model_{name}.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7b81573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"t\", Actual: \"t\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x221eb264520>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbl0lEQVR4nO3df2xV9f3H8dcttBfU9tZa29srBcsPYeHXMiZdgyKOBugyJsof/iAZLEwGK2bQOUkXFd2PVPkmalw6/GeBmQg4EoHIMhatto1bwYAQfmxraFP5EWhRst5bipQf9/P9g3jnlQKey719t5fnI/kkveec9z3vHg599dx7+rk+55wTAAB9LMO6AQDAzYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgInB1g18XTQa1YkTJ5SdnS2fz2fdDgDAI+ecurq6FAqFlJFx9eucfhdAJ06cUHFxsXUbAIAbdOzYMQ0bNuyq6/vdS3DZ2dnWLQAAkuB6P89TFkC1tbW6++67NWTIEJWWlurjjz/+RnW87AYA6eF6P89TEkBvv/22qqqqtHr1an3yySeaPHmyZs+erVOnTqVidwCAgcilwNSpU11lZWXs8aVLl1woFHI1NTXXrQ2Hw04Sg8FgMAb4CIfD1/x5n/QroPPnz2vPnj0qLy+PLcvIyFB5ebmampqu2L6np0eRSCRuAADSX9ID6PPPP9elS5dUWFgYt7ywsFDt7e1XbF9TU6NAIBAb3AEHADcH87vgqqurFQ6HY+PYsWPWLQEA+kDS/w4oPz9fgwYNUkdHR9zyjo4OBYPBK7b3+/3y+/3JbgMA0M8l/QooKytLU6ZMUV1dXWxZNBpVXV2dysrKkr07AMAAlZKZEKqqqrRw4UJ997vf1dSpU/Xaa6+pu7tbP/nJT1KxOwDAAJSSAHr00Uf12Wef6fnnn1d7e7u+/e1va8eOHVfcmAAAuHn5nHPOuomvikQiCgQC1m0A39i1JltMpmg02if7AZIlHA4rJyfnquvN74IDANycCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmEjJbNiAtUQnCF2+fLnnmunTp3uuiUQinmt+//vfe65pbW31XAP0Fa6AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmmA0baSnR2bB/9rOfea4ZO3as55qenh7PNYn46U9/mlBdNBpNcifAlbgCAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILJSIGvGDzY+3+JRCY+HTp0qOeaadOmea5JdFJWJiNFX+AKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJpIeQC+88IJ8Pl/cGDduXLJ3AwAY4FLygXTjx4/X+++//7+dJPAhXwCA9JaSZBg8eLCCwWAqnhoAkCZS8h7Q4cOHFQqFNHLkSC1YsEBHjx696rY9PT2KRCJxAwCQ/pIeQKWlpVq/fr127NihtWvXqq2tTffff7+6urp63b6mpkaBQCA2iouLk90SAKAf8jnnXCp30NnZqREjRuiVV17R4sWLr1jf09Ojnp6e2ONIJEII4YYl+r7joUOHPNeMGTMmoX15dfjwYc8148ePT2hfFy9eTKgO+KpwOKycnJyrrk/53QG5ubm655571NLS0ut6v98vv9+f6jYAAP1Myv8O6MyZM2ptbVVRUVGqdwUAGECSHkBPP/20Ghoa9Omnn+qf//ynHn74YQ0aNEiPP/54sncFABjAkv4S3PHjx/X444/r9OnTuvPOO3Xfffdp586duvPOO5O9KwDAAJb0ANq0aVOynxIAkIaYCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJlH8gHYDkiEQi1i0AScUVEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABLNhA18RjUb7ZD8XL170XNPQ0NAn+wH6CldAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAZKdJSopNw/vWvf/VcM2rUqIT25VVXV1ef7AfoK1wBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAhOcAamxs1Ny5cxUKheTz+bR169a49c45Pf/88yoqKtLQoUNVXl6uw4cPJ6tfAECa8BxA3d3dmjx5smpra3tdv2bNGr3++ut64403tGvXLt16662aPXu2zp07d8PNAgDSh+dPRK2oqFBFRUWv65xzeu211/Tss8/qoYcekiS9+eabKiws1NatW/XYY4/dWLcAgLSR1PeA2tra1N7ervLy8tiyQCCg0tJSNTU19VrT09OjSCQSNwAA6S+pAdTe3i5JKiwsjFteWFgYW/d1NTU1CgQCsVFcXJzMlgAA/ZT5XXDV1dUKh8OxcezYMeuWAAB9IKkBFAwGJUkdHR1xyzs6OmLrvs7v9ysnJyduAADSX1IDqKSkRMFgUHV1dbFlkUhEu3btUllZWTJ3BQAY4DzfBXfmzBm1tLTEHre1tWnfvn3Ky8vT8OHDtWLFCv3ud7/TmDFjVFJSoueee06hUEjz5s1LZt8AgAHOcwDt3r1bDz74YOxxVVWVJGnhwoVav369nnnmGXV3d2vJkiXq7OzUfffdpx07dmjIkCHJ6xoAMOD5nHPOuomvikQiCgQC1m1ggBs82PPvVpKkAwcOeK4ZO3as55rPPvvMc83SpUs912zZssVzDZAs4XD4mu/rm98FBwC4ORFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATCQ2ZTD6Lb/f77mmuLg4oX2Fw2HPNYnMAt2XMjL65ney//73v55rDh06lIJOADtcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBZKT9WH5+vueaNWvWeK5ZsGCB5xopsQk1V61a5bnmb3/7m+eaSCTiuaYvbd++3XPNsWPHUtAJYIcrIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaYjLQfy83N9VxTVlbmuSYzM9NzjSQVFBR4rnn55Zc91/zwhz/0XLNjxw7PNZJ0++23J1TnVVZWlueau+66y3PNkSNHPNdIknPOc000Gu2TGqQProAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8LlEZh1MoUgkokAgYN1GvzB69GjPNe+++67nmrFjx3qukSSfz+e5pq9Ot0T3k8j3lIhEJuHs6enxXHP8+HHPNVJi/R06dMhzzYEDBzzXJKKxsTGhuoaGBs81TLD6P+FwWDk5OVddzxUQAMAEAQQAMOE5gBobGzV37lyFQiH5fD5t3bo1bv2iRYvk8/nixpw5c5LVLwAgTXgOoO7ubk2ePFm1tbVX3WbOnDk6efJkbGzcuPGGmgQApB/Pn4haUVGhioqKa27j9/sVDAYTbgoAkP5S8h5QfX29CgoKNHbsWC1btkynT5++6rY9PT2KRCJxAwCQ/pIeQHPmzNGbb76puro6vfzyy2poaFBFRYUuXbrU6/Y1NTUKBAKxUVxcnOyWAAD9kOeX4K7nsccei309ceJETZo0SaNGjVJ9fb1mzpx5xfbV1dWqqqqKPY5EIoQQANwEUn4b9siRI5Wfn6+WlpZe1/v9fuXk5MQNAED6S3kAHT9+XKdPn1ZRUVGqdwUAGEA8vwR35syZuKuZtrY27du3T3l5ecrLy9OLL76o+fPnKxgMqrW1Vc8884xGjx6t2bNnJ7VxAMDA5jmAdu/erQcffDD2+Mv3bxYuXKi1a9dq//79+vOf/6zOzk6FQiHNmjVLv/3tb+X3+5PXNQBgwPMcQDNmzLjmRI9///vfb6gh/E9nZ6fnmqamJs81I0eO9Fwj9d3EnYkYPDjp99ckVUaG91e/hw4d6rlmzJgxnmsSlci+fvSjH3muSWSi2WHDhnmukaS9e/d6rknk/+3NirngAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmfC6RqWVTKBKJKBAIWLcxYCXysRf9/SPQEzkf5s6dm9C+Vq1a5bkmkWPe0NDguaaxsdFzTaLGjx/fJzWJOHDggOeaZ555JqF9HTlyxHNNP/uRaiocDl/zU665AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGBisHUDSK6enh7PNS0tLSnoxFZzc3NCdT/+8Y8919x9992eaxKZWPSll17yXHPx4kXPNZKUm5vruaavJhEOh8Oeaz777LMUdIIbxRUQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE0xGirR07ty5hOouXLiQ5E56F41GPdck0luik5EmMnknE37CK66AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGAyUqSlzMzMPq0D4B1XQAAAEwQQAMCEpwCqqanRvffeq+zsbBUUFGjevHlqbm6O2+bcuXOqrKzUHXfcodtuu03z589XR0dHUpsGAAx8ngKooaFBlZWV2rlzp9577z1duHBBs2bNUnd3d2yblStX6t1339XmzZvV0NCgEydO6JFHHkl64wCAgc3TTQg7duyIe7x+/XoVFBRoz549mj59usLhsP70pz9pw4YN+v73vy9JWrdunb71rW9p586d+t73vpe8zgEAA9oNvQcUDoclSXl5eZKkPXv26MKFCyovL49tM27cOA0fPlxNTU29PkdPT48ikUjcAACkv4QDKBqNasWKFZo2bZomTJggSWpvb1dWVpZyc3Pjti0sLFR7e3uvz1NTU6NAIBAbxcXFibYEABhAEg6gyspKHTx4UJs2bbqhBqqrqxUOh2Pj2LFjN/R8AICBIaE/RF2+fLm2b9+uxsZGDRs2LLY8GAzq/Pnz6uzsjLsK6ujoUDAY7PW5/H6//H5/Im0AAAYwT1dAzjktX75cW7Zs0QcffKCSkpK49VOmTFFmZqbq6upiy5qbm3X06FGVlZUlp2MAQFrwdAVUWVmpDRs2aNu2bcrOzo69rxMIBDR06FAFAgEtXrxYVVVVysvLU05Ojp566imVlZVxBxwAII6nAFq7dq0kacaMGXHL161bp0WLFkmSXn31VWVkZGj+/Pnq6enR7Nmz9cc//jEpzQIA0oenAHLOXXebIUOGqLa2VrW1tQk3BdyoL/80oK/qAHjHXHAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMJfSIq0N+dOnUqobqOjg7PNTk5OZ5rsrOzPddkZmZ6rrl48aLnGqCvcAUEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORIi0556xbuKYHHnjAc01hYaHnmk8//dRzDdBXuAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggslIga8Ih8Oea/r7xKdAf8UVEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRoq0dPHixYTqXn31Vc81K1eu9FyzZcsWzzXt7e2ea4D+jCsgAIAJAggAYMJTANXU1Ojee+9Vdna2CgoKNG/ePDU3N8dtM2PGDPl8vrixdOnSpDYNABj4PAVQQ0ODKisrtXPnTr333nu6cOGCZs2ape7u7rjtnnzySZ08eTI21qxZk9SmAQADn6ebEHbs2BH3eP369SooKNCePXs0ffr02PJbbrlFwWAwOR0CANLSDb0H9OXHF+fl5cUtf+utt5Sfn68JEyaourpaZ8+evepz9PT0KBKJxA0AQPpL+DbsaDSqFStWaNq0aZowYUJs+RNPPKERI0YoFApp//79WrVqlZqbm/XOO+/0+jw1NTV68cUXE20DADBAJRxAlZWVOnjwoD766KO45UuWLIl9PXHiRBUVFWnmzJlqbW3VqFGjrnie6upqVVVVxR5HIhEVFxcn2hYAYIBIKICWL1+u7du3q7GxUcOGDbvmtqWlpZKklpaWXgPI7/fL7/cn0gYAYADzFEDOOT311FPasmWL6uvrVVJSct2affv2SZKKiooSahAAkJ48BVBlZaU2bNigbdu2KTs7OzY1SCAQ0NChQ9Xa2qoNGzboBz/4ge644w7t379fK1eu1PTp0zVp0qSUfAMAgIHJUwCtXbtW0uU/Nv2qdevWadGiRcrKytL777+v1157Td3d3SouLtb8+fP17LPPJq1hAEB68PwS3LUUFxeroaHhhhoCANwcfO56qdLHIpGIAoGAdRvANzZ4sPd7eaLRaJ/UAJbC4bBycnKuup7JSAEAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhI+CO5AVx28eJF6xaAAYkrIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY6HcB5JyzbgEAkATX+3ne7wKoq6vLugUAQBJc7+e5z/WzS45oNKoTJ04oOztbPp8vbl0kElFxcbGOHTumnJwcow7tcRwu4zhcxnG4jONwWX84Ds45dXV1KRQKKSPj6tc5/e7jGDIyMjRs2LBrbpOTk3NTn2Bf4jhcxnG4jONwGcfhMuvjEAgErrtNv3sJDgBwcyCAAAAmBlQA+f1+rV69Wn6/37oVUxyHyzgOl3EcLuM4XDaQjkO/uwkBAHBzGFBXQACA9EEAAQBMEEAAABMEEADAxIAJoNraWt19990aMmSISktL9fHHH1u31OdeeOEF+Xy+uDFu3DjrtlKusbFRc+fOVSgUks/n09atW+PWO+f0/PPPq6ioSEOHDlV5ebkOHz5s02wKXe84LFq06IrzY86cOTbNpkhNTY3uvfdeZWdnq6CgQPPmzVNzc3PcNufOnVNlZaXuuOMO3XbbbZo/f746OjqMOk6Nb3IcZsyYccX5sHTpUqOOezcgAujtt99WVVWVVq9erU8++USTJ0/W7NmzderUKevW+tz48eN18uTJ2Pjoo4+sW0q57u5uTZ48WbW1tb2uX7NmjV5//XW98cYb2rVrl2699VbNnj1b586d6+NOU+t6x0GS5syZE3d+bNy4sQ87TL2GhgZVVlZq586deu+993ThwgXNmjVL3d3dsW1Wrlypd999V5s3b1ZDQ4NOnDihRx55xLDr5Psmx0GSnnzyybjzYc2aNUYdX4UbAKZOneoqKytjjy9duuRCoZCrqakx7KrvrV692k2ePNm6DVOS3JYtW2KPo9GoCwaD7v/+7/9iyzo7O53f73cbN2406LBvfP04OOfcwoUL3UMPPWTSj5VTp045Sa6hocE5d/nfPjMz023evDm2zb///W8nyTU1NVm1mXJfPw7OOffAAw+4X/ziF3ZNfQP9/gro/Pnz2rNnj8rLy2PLMjIyVF5erqamJsPObBw+fFihUEgjR47UggULdPToUeuWTLW1tam9vT3u/AgEAiotLb0pz4/6+noVFBRo7NixWrZsmU6fPm3dUkqFw2FJUl5eniRpz549unDhQtz5MG7cOA0fPjytz4evH4cvvfXWW8rPz9eECRNUXV2ts2fPWrR3Vf1uMtKv+/zzz3Xp0iUVFhbGLS8sLNR//vMfo65slJaWav369Ro7dqxOnjypF198Uffff78OHjyo7Oxs6/ZMtLe3S1Kv58eX624Wc+bM0SOPPKKSkhK1trbq17/+tSoqKtTU1KRBgwZZt5d00WhUK1as0LRp0zRhwgRJl8+HrKws5ebmxm2bzudDb8dBkp544gmNGDFCoVBI+/fv16pVq9Tc3Kx33nnHsNt4/T6A8D8VFRWxrydNmqTS0lKNGDFCf/nLX7R48WLDztAfPPbYY7GvJ06cqEmTJmnUqFGqr6/XzJkzDTtLjcrKSh08ePCmeB/0Wq52HJYsWRL7euLEiSoqKtLMmTPV2tqqUaNG9XWbver3L8Hl5+dr0KBBV9zF0tHRoWAwaNRV/5Cbm6t77rlHLS0t1q2Y+fIc4Py40siRI5Wfn5+W58fy5cu1fft2ffjhh3Ef3xIMBnX+/Hl1dnbGbZ+u58PVjkNvSktLJalfnQ/9PoCysrI0ZcoU1dXVxZZFo1HV1dWprKzMsDN7Z86cUWtrq4qKiqxbMVNSUqJgMBh3fkQiEe3ateumPz+OHz+u06dPp9X54ZzT8uXLtWXLFn3wwQcqKSmJWz9lyhRlZmbGnQ/Nzc06evRoWp0P1zsOvdm3b58k9a/zwfouiG9i06ZNzu/3u/Xr17t//etfbsmSJS43N9e1t7dbt9anfvnLX7r6+nrX1tbm/vGPf7jy8nKXn5/vTp06Zd1aSnV1dbm9e/e6vXv3OknulVdecXv37nVHjhxxzjn30ksvudzcXLdt2za3f/9+99BDD7mSkhL3xRdfGHeeXNc6Dl1dXe7pp592TU1Nrq2tzb3//vvuO9/5jhszZow7d+6cdetJs2zZMhcIBFx9fb07efJkbJw9eza2zdKlS93w4cPdBx984Hbv3u3KyspcWVmZYdfJd73j0NLS4n7zm9+43bt3u7a2Nrdt2zY3cuRIN336dOPO4w2IAHLOuT/84Q9u+PDhLisry02dOtXt3LnTuqU+9+ijj7qioiKXlZXl7rrrLvfoo4+6lpYW67ZS7sMPP3SSrhgLFy50zl2+Ffu5555zhYWFzu/3u5kzZ7rm5mbbplPgWsfh7NmzbtasWe7OO+90mZmZbsSIEe7JJ59Mu1/Sevv+Jbl169bFtvniiy/cz3/+c3f77be7W265xT388MPu5MmTdk2nwPWOw9GjR9306dNdXl6e8/v9bvTo0e5Xv/qVC4fDto1/DR/HAAAw0e/fAwIApCcCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAm/h9yP9t+F2bo4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "idx = np.random.randint(0, len(test_data))\n",
    "x, y = test_data[idx]\n",
    "with torch.no_grad():\n",
    "    x = x.unsqueeze(0)\n",
    "    pred = model(x.to(device))\n",
    "    predicted, actual = class_names[pred[0].argmax(0)], class_names[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "plt.imshow(x.reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef38688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fab490ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_class = \"l\"\n",
    "# targets = []\n",
    "# for img, label in test_data:\n",
    "#     label = label.item()\n",
    "#     class_name = class_names[label]\n",
    "#     if class_name == target_class:\n",
    "#         targets.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6433c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.random.randint(0, len(targets))\n",
    "# plt.imshow(targets[idx].reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71985a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r': 2400, 'a': 2400, 'n': 2400, 'F': 2400, '4': 2400, 'h': 2400, 'Q': 2400, 'W': 2400, 'K': 2400, '1': 2400, 't': 2400, 'D': 2400, 'O': 2400, 'C': 2400, '5': 2400, 'H': 2400, '3': 2400, 'f': 2400, 'E': 2400, 'q': 2400, 'J': 2400, 'T': 2400, 'P': 2400, 'Z': 2400, 'S': 2400, 'N': 2400, 'M': 2400, 'Y': 2400, '9': 2400, 'U': 2400, 'd': 2400, 'e': 2400, 'b': 2400, 'V': 2400, 'G': 2400, '7': 2400, '2': 2400, '8': 2400, 'A': 2400, '6': 2400, 'R': 2400, 'X': 2400, 'B': 2400, 'I': 2400, 'g': 2400, '0': 2400, 'L': 2400, 'gt': 232, 'colon': 99}\n"
     ]
    }
   ],
   "source": [
    "counts = dict()\n",
    "for img, label in train_data:\n",
    "    class_name = class_names[label.item()]\n",
    "    counts[class_name] = counts.get(class_name, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb427c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmpe295",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
